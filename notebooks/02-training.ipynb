{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "416b5048ed2c04c7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/talhaakhoon/Documents/Dev/pneumonia_x_ray_images_classifier/data/processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch import optim, nn\n",
    "\n",
    "from pneumonia_x_ray_images_classifier.modeling.model import PneumoniaClassifierModel\n",
    "from torchvision import transforms\n",
    "\n",
    "from pneumonia_x_ray_images_classifier.data.make_dataset import get_latest_pneumonia_dataset\n",
    "from pneumonia_x_ray_images_classifier.dataset import PneumoniaDataset\n",
    "from pneumonia_x_ray_images_classifier.config import PROJ_ROOT\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = get_latest_pneumonia_dataset()\n",
    "print(root_dir)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_dataset = PneumoniaDataset(root_dir, split='train', transform=train_transforms)\n",
    "val_dataset = PneumoniaDataset(root_dir, split='val', transform=val_transforms)\n",
    "\n",
    "train_dataset_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "def make_model(learning_rate=1e-3, dropout=0.0, freeze_bn=True, unfreeze_last_n: int = 0, weight_decay: float = 0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = PneumoniaClassifierModel(dropout=dropout, freeze_backbone=freeze_bn, unfreeze_last_n=unfreeze_last_n)\n",
    "    model.to(device)\n",
    "\n",
    "    optimiser = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate,\n",
    "                           weight_decay=weight_decay)\n",
    "\n",
    "    return model, optimiser, device\n",
    "\n",
    "\n",
    "def train_and_evaluate(name: str, model: nn.Module, optimizer: Optimizer, criterion,\n",
    "                       train_loader: torch.utils.data.DataLoader, val_loader: torch.utils.data.DataLoader,\n",
    "                       device: torch.device, num_epochs: int, enable_checkpointing=False):\n",
    "    best_val_recall = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0\n",
    "        train_running_corrects = 0\n",
    "        train_running_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += loss.item()\n",
    "            _, predicted_indices = torch.max(outputs.data, 1)\n",
    "            train_running_total += labels.size(0)\n",
    "            train_running_corrects += (predicted_indices == labels).sum().item()\n",
    "\n",
    "        train_loss = train_running_loss / len(train_loader)\n",
    "        train_acc = train_running_corrects / train_running_total\n",
    "\n",
    "        #Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0\n",
    "        val_running_corrects = 0\n",
    "        val_running_total = 0\n",
    "        tp = 0\n",
    "        fn = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item()\n",
    "                _, predicted_indices = torch.max(outputs, 1)\n",
    "                val_running_total += labels.size(0)\n",
    "                val_running_corrects += (predicted_indices == labels).sum().item()\n",
    "\n",
    "                pneu = (labels == 1)\n",
    "                tp += ((predicted_indices == 1) & pneu).sum().item()  #Correctly predicted pneumonia cases\n",
    "                fn += ((predicted_indices == 0) & pneu).sum().item()  #Missed pneumonia cases (the dangerous ones)\n",
    "\n",
    "            val_loss = val_running_loss / len(val_loader)\n",
    "            val_acc = val_running_corrects / val_running_total\n",
    "            val_recall = tp / (tp + fn)  # how many were correctly predicted from all positive cases\n",
    "\n",
    "            print(f'Epoch: {epoch + 1}')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}')\n",
    "            print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}, Val Recall(PNEU): {val_recall:.4f}')\n",
    "\n",
    "        if enable_checkpointing and (val_recall > best_val_recall):\n",
    "            best_val_recall = val_recall\n",
    "            checkpoint_path = PROJ_ROOT / \"models\" / \"checkpoints\" / f'{name}_{epoch + 1:02d}_recall{val_recall:04f}.pth'\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Model saved to {checkpoint_path}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-19T18:18:27.225108Z",
     "start_time": "2026-01-19T18:18:27.135489Z"
    }
   },
   "id": "6339f34b896a654d",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 1. Training Baseline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80ad9e37102268ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.2361, Train Accuracy: 0.9065\n",
      "Val Loss: 0.1332, Val Accuracy: 0.9540, Val Recall(PNEU): 0.9755\n",
      "Model saved to models/checkpoints/mobilenet_v2_lr0.001_drop0.0_frozen_best_01_recall0.975515.pth\n",
      "Epoch: 2\n",
      "Train Loss: 0.1608, Train Accuracy: 0.9341\n",
      "Val Loss: 0.1147, Val Accuracy: 0.9617, Val Recall(PNEU): 0.9742\n",
      "Epoch: 3\n",
      "Train Loss: 0.1551, Train Accuracy: 0.9415\n",
      "Val Loss: 0.1044, Val Accuracy: 0.9626, Val Recall(PNEU): 0.9832\n",
      "Model saved to models/checkpoints/mobilenet_v2_lr0.001_drop0.0_frozen_best_03_recall0.983247.pth\n",
      "Epoch: 4\n",
      "Train Loss: 0.1255, Train Accuracy: 0.9487\n",
      "Val Loss: 0.0989, Val Accuracy: 0.9655, Val Recall(PNEU): 0.9794\n",
      "Epoch: 5\n",
      "Train Loss: 0.1277, Train Accuracy: 0.9485\n",
      "Val Loss: 0.0962, Val Accuracy: 0.9626, Val Recall(PNEU): 0.9755\n",
      "Epoch: 6\n",
      "Train Loss: 0.1342, Train Accuracy: 0.9492\n",
      "Val Loss: 0.0985, Val Accuracy: 0.9655, Val Recall(PNEU): 0.9729\n",
      "Epoch: 7\n",
      "Train Loss: 0.1147, Train Accuracy: 0.9569\n",
      "Val Loss: 0.1006, Val Accuracy: 0.9579, Val Recall(PNEU): 0.9858\n",
      "Model saved to models/checkpoints/mobilenet_v2_lr0.001_drop0.0_frozen_best_07_recall0.985825.pth\n",
      "Epoch: 8\n",
      "Train Loss: 0.1115, Train Accuracy: 0.9561\n",
      "Val Loss: 0.0937, Val Accuracy: 0.9617, Val Recall(PNEU): 0.9794\n",
      "Epoch: 9\n",
      "Train Loss: 0.1079, Train Accuracy: 0.9554\n",
      "Val Loss: 0.0906, Val Accuracy: 0.9636, Val Recall(PNEU): 0.9832\n",
      "Epoch: 10\n",
      "Train Loss: 0.1061, Train Accuracy: 0.9559\n",
      "Val Loss: 0.0905, Val Accuracy: 0.9665, Val Recall(PNEU): 0.9742\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Path('models/checkpoints').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lr = 1e-3\n",
    "dr = 0.0\n",
    "freeze_backbone = True\n",
    "model, optimizer, device = make_model(learning_rate=lr, dropout=dr, freeze_bn=freeze_backbone)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_and_evaluate(\n",
    "    enable_checkpointing=True,\n",
    "    name=f\"mobilenet_v2_lr{lr}_drop{dr}_{'' if freeze_backbone else 'Un'}frozen_best\",\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_dataset_loader,\n",
    "    val_loader=val_dataset_loader,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-18T23:13:09.399550Z",
     "start_time": "2026-01-18T22:30:34.463790Z"
    }
   },
   "id": "a718338a03651d2a",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model converged rapidly within the first few epochs, which is expected when training only a small classifier head on top of a pretrained backbone.\n",
    "\n",
    "Training and validation losses decreased consistently across epochs, with no sustained divergence between them.\n",
    "\n",
    "Validation accuracy remained stable in the mid-90% range throughout training.\n",
    "\n",
    "Validation recall for pneumonia was consistently high (≈97–99%), indicating strong sensitivity to positive cases.\n",
    "\n",
    "Even though the baseline generalises well, would explicit regularisation reduce variance and stabilise recall? Next model with standard strong regulariser drop rate of 0.5 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afa565c9fb4462e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 2. Training Baseline Model with Regularisation 0.5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "715d38a99365cc35"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.2648, Train Accuracy: 0.8871\n",
      "Val Loss: 0.1388, Val Accuracy: 0.9550, Val Recall(PNEU): 0.9729\n",
      "Model saved to models/checkpoints/mobilenet_v2_lr0.001_drop0.5_frozen_best_01_recall0.972938.pth\n",
      "Epoch: 2\n",
      "Train Loss: 0.1886, Train Accuracy: 0.9240\n",
      "Val Loss: 0.1294, Val Accuracy: 0.9598, Val Recall(PNEU): 0.9678\n",
      "Epoch: 3\n",
      "Train Loss: 0.1739, Train Accuracy: 0.9298\n",
      "Val Loss: 0.1210, Val Accuracy: 0.9607, Val Recall(PNEU): 0.9704\n",
      "Epoch: 4\n",
      "Train Loss: 0.1683, Train Accuracy: 0.9355\n",
      "Val Loss: 0.1303, Val Accuracy: 0.9540, Val Recall(PNEU): 0.9510\n",
      "Epoch: 5\n",
      "Train Loss: 0.2011, Train Accuracy: 0.9190\n",
      "Val Loss: 0.1023, Val Accuracy: 0.9636, Val Recall(PNEU): 0.9807\n",
      "Model saved to models/checkpoints/mobilenet_v2_lr0.001_drop0.5_frozen_best_05_recall0.980670.pth\n",
      "Epoch: 6\n",
      "Train Loss: 0.1714, Train Accuracy: 0.9350\n",
      "Val Loss: 0.1399, Val Accuracy: 0.9531, Val Recall(PNEU): 0.9472\n",
      "Epoch: 7\n",
      "Train Loss: 0.1668, Train Accuracy: 0.9338\n",
      "Val Loss: 0.1070, Val Accuracy: 0.9646, Val Recall(PNEU): 0.9755\n",
      "Epoch: 8\n",
      "Train Loss: 0.1545, Train Accuracy: 0.9379\n",
      "Val Loss: 0.1001, Val Accuracy: 0.9636, Val Recall(PNEU): 0.9807\n",
      "Epoch: 9\n",
      "Train Loss: 0.1704, Train Accuracy: 0.9329\n",
      "Val Loss: 0.1029, Val Accuracy: 0.9665, Val Recall(PNEU): 0.9729\n",
      "Epoch: 10\n",
      "Train Loss: 0.1599, Train Accuracy: 0.9377\n",
      "Val Loss: 0.1136, Val Accuracy: 0.9655, Val Recall(PNEU): 0.9652\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "dr = 0.5\n",
    "freeze_backbone = True\n",
    "model, optimizer, device = make_model(learning_rate=lr, dropout=dr, freeze_bn=freeze_backbone)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_and_evaluate(\n",
    "    enable_checkpointing=True,\n",
    "    name=f\"mobilenet_v2_lr{lr}_drop{dr}_{'' if freeze_backbone else 'Un'}frozen_best\",\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_dataset_loader,\n",
    "    val_loader=val_dataset_loader,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-19T00:07:21.136188Z",
     "start_time": "2026-01-18T23:25:04.201485Z"
    }
   },
   "id": "a6c0f33ba240de84",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding dropout (0.5) to the frozen-head baseline did not improve validation recall, suggesting the baseline already generalised well and extra regularisation reduced sensitivity."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5efbe610f91eb17"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.1639, Train Accuracy: 0.9350\n",
      "Val Loss: 0.0685, Val Accuracy: 0.9732, Val Recall(PNEU): 0.9871\n",
      "Model saved to /Users/talhaakhoon/Documents/Dev/pneumonia_x_ray_images_classifier/models/checkpoints/mobilenet_v2_lr0.0001_drop0.5_Unfrozen_layers_3_best_01_recall0.987113.pth\n",
      "Epoch: 2\n",
      "Train Loss: 0.0788, Train Accuracy: 0.9720\n",
      "Val Loss: 0.0555, Val Accuracy: 0.9799, Val Recall(PNEU): 0.9820\n",
      "Epoch: 3\n",
      "Train Loss: 0.0439, Train Accuracy: 0.9854\n",
      "Val Loss: 0.0561, Val Accuracy: 0.9780, Val Recall(PNEU): 0.9794\n",
      "Epoch: 4\n",
      "Train Loss: 0.0324, Train Accuracy: 0.9904\n",
      "Val Loss: 0.0426, Val Accuracy: 0.9856, Val Recall(PNEU): 0.9897\n",
      "Model saved to /Users/talhaakhoon/Documents/Dev/pneumonia_x_ray_images_classifier/models/checkpoints/mobilenet_v2_lr0.0001_drop0.5_Unfrozen_layers_3_best_04_recall0.989691.pth\n",
      "Epoch: 5\n",
      "Train Loss: 0.0166, Train Accuracy: 0.9940\n",
      "Val Loss: 0.0534, Val Accuracy: 0.9789, Val Recall(PNEU): 0.9948\n",
      "Model saved to /Users/talhaakhoon/Documents/Dev/pneumonia_x_ray_images_classifier/models/checkpoints/mobilenet_v2_lr0.0001_drop0.5_Unfrozen_layers_3_best_05_recall0.994845.pth\n",
      "Epoch: 6\n",
      "Train Loss: 0.0147, Train Accuracy: 0.9950\n",
      "Val Loss: 0.0435, Val Accuracy: 0.9856, Val Recall(PNEU): 0.9910\n",
      "Epoch: 7\n",
      "Train Loss: 0.0111, Train Accuracy: 0.9971\n",
      "Val Loss: 0.0681, Val Accuracy: 0.9799, Val Recall(PNEU): 0.9884\n",
      "Epoch: 8\n",
      "Train Loss: 0.0120, Train Accuracy: 0.9971\n",
      "Val Loss: 0.0635, Val Accuracy: 0.9808, Val Recall(PNEU): 0.9910\n",
      "Epoch: 9\n",
      "Train Loss: 0.0114, Train Accuracy: 0.9971\n",
      "Val Loss: 0.0490, Val Accuracy: 0.9818, Val Recall(PNEU): 0.9936\n",
      "Epoch: 10\n",
      "Train Loss: 0.0089, Train Accuracy: 0.9978\n",
      "Val Loss: 0.0361, Val Accuracy: 0.9847, Val Recall(PNEU): 0.9936\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "dr = 0.5\n",
    "freeze_backbone = False\n",
    "unfreeze_layers = 3\n",
    "decay = 1e-4\n",
    "model, optimizer, device = make_model(learning_rate=lr, dropout=dr, freeze_bn=freeze_backbone,\n",
    "                                      unfreeze_last_n=unfreeze_layers, weight_decay=decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_and_evaluate(\n",
    "    enable_checkpointing=True,\n",
    "    name=f\"mobilenet_v2_lr{lr}_drop{dr}_{'' if freeze_backbone else 'Un'}frozen_layers_{unfreeze_layers}_best\",\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_dataset_loader,\n",
    "    val_loader=val_dataset_loader,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-19T20:12:26.274852Z",
     "start_time": "2026-01-19T18:18:32.106786Z"
    }
   },
   "id": "3fce0e3f2e148f1f",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best model seems to be mobilenet_v2_lr0.0001_drop0.5_Unfrozen_layers_3_best_05_recall0.994845.pth"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c425cd41a8b39908"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
